#!/usr/bin/env python3

import sys, argparse

def index_new(file_in, file_out):
    vocab = dict()
    def id(token):
        if token not in vocab: vocab[token] = str(len(vocab))
        return vocab[token]

    for line in file_in:
        tokens = line.strip().split()
        file_out.write(' '.join([id(token) for token in tokens]) + '\n')
    
    return vocab

def index(vocab, file_in, file_out):
    for line in file_in:
        tokens = line.strip().split()
        file_out.write(' '.join([vocab[token] for token in tokens if token in vocab]) + '\n')

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('vocab', help='word-id lookup file')
    parser.add_argument('-n', '--new-vocab', dest='create_new', action='store_true', help='create new vocab file instead of reading an existing one')
    parser.add_argument('-i', '--in', dest='filename_in', metavar='file', type=str, help='file to read documents from (stdin if omitted)')
    parser.add_argument('-o', '--out', dest='filename_out', metavar='file', type=str, help='file to outputs indeces to (stdout if omitted)')

    args = parser.parse_args()
    file_in = open(args.filename_in, 'r') if args.filename_in else sys.stdin
    file_out = open(args.filename_out, 'w') if args.filename_out else sys.stdout

    if args.create_new:
        vocab = index_new(file_in, file_out)
        with open(args.vocab, 'w') as vocab_fp:
            vocab_fp.write('\n'.join([
                f'{id}\t{token}' for token, id in sorted(vocab.items(), key=lambda v: v[1])
            ]))
        
    else:
        with open(args.vocab, 'r') as vocab_fp:
            vocab = dict([
                line.strip().split('\t')[::-1]
            for line in vocab_fp])
        index(file_in, file_out)

